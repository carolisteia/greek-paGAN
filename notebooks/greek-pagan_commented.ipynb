{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4ee6a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T10:38:00.067071Z",
     "iopub.status.busy": "2024-06-27T10:38:00.066777Z",
     "iopub.status.idle": "2024-06-27T10:38:12.149221Z",
     "shell.execute_reply": "2024-06-27T10:38:12.148450Z"
    },
    "executionInfo": {
     "elapsed": 10793,
     "status": "ok",
     "timestamp": 1718625099885,
     "user": {
      "displayName": "Clémence F",
      "userId": "02328509030226210452"
     },
     "user_tz": -120
    },
    "id": "DjAgtYvIMTqD",
    "papermill": {
     "duration": 12.094671,
     "end_time": "2024-06-27T10:38:12.151467",
     "exception": false,
     "start_time": "2024-06-27T10:38:00.056796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 10:38:01.686359: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-27 10:38:01.686464: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-27 10:38:01.797940: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "# INSTALL LIBRARIES\n",
    "##################\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa02d015",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T10:38:12.170485Z",
     "iopub.status.busy": "2024-06-27T10:38:12.169997Z",
     "iopub.status.idle": "2024-06-27T10:38:12.178277Z",
     "shell.execute_reply": "2024-06-27T10:38:12.177423Z"
    },
    "papermill": {
     "duration": 0.019821,
     "end_time": "2024-06-27T10:38:12.180291",
     "exception": false,
     "start_time": "2024-06-27T10:38:12.160470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_dataset(data_path):\n",
    "    \"\"\"\n",
    "    Loads an image training dataset from the specified directory.\n",
    "\n",
    "    Parameters:\n",
    "    - data_path (str): Path to the directory containing the image files.\n",
    "\n",
    "    Returns:\n",
    "    - train_dataset: A tf.data.Dataset object containing the loaded images along with their labels.\n",
    "    \"\"\"\n",
    "    # Load the training dataset from the specified directory\n",
    "    train_dataset = image_dataset_from_directory(\n",
    "        data_path,\n",
    "        labels='inferred',  # Infer labels from the directory structure\n",
    "        label_mode='int',   # Labels are returned as integers (for classification tasks)\n",
    "        image_size=(64, 64),  # Resize images to 64x64 (corrected from the mismatched comment)\n",
    "        color_mode='rgb',  # Use RGB color mode\n",
    "        batch_size=32,  # Number of samples per batch\n",
    "        shuffle=True,  # Shuffle the dataset\n",
    "        seed=42,  # Seed used for shuffling and transformations\n",
    "        validation_split=0.0,  # No splitting; all data used as training set\n",
    "        subset=None,  # Subset of data to use ('training' or 'validation'), not used here\n",
    "    )\n",
    "\n",
    "    # Initialize lists to store batched data\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    # Iterate through the dataset and collect all data into lists\n",
    "    for images, labels in train_dataset:\n",
    "        X_train.append(images.numpy())\n",
    "        y_train.append(labels.numpy())\n",
    "\n",
    "    # Convert lists to a single numpy array\n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = np.concatenate(y_train)\n",
    "\n",
    "    # Normalize images to range [-1, 1]\n",
    "    X_train = (X_train / 127.5) - 1\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "# Remember to adjust the normalization and image size as necessary based on your specific use case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "290e97d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T10:38:12.198476Z",
     "iopub.status.busy": "2024-06-27T10:38:12.198204Z",
     "iopub.status.idle": "2024-06-27T10:38:12.201871Z",
     "shell.execute_reply": "2024-06-27T10:38:12.201039Z"
    },
    "papermill": {
     "duration": 0.0151,
     "end_time": "2024-06-27T10:38:12.203845",
     "exception": false,
     "start_time": "2024-06-27T10:38:12.188745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94cbada3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T10:38:12.221741Z",
     "iopub.status.busy": "2024-06-27T10:38:12.221499Z",
     "iopub.status.idle": "2024-06-27T10:38:12.225343Z",
     "shell.execute_reply": "2024-06-27T10:38:12.224537Z"
    },
    "papermill": {
     "duration": 0.01498,
     "end_time": "2024-06-27T10:38:12.227247",
     "exception": false,
     "start_time": "2024-06-27T10:38:12.212267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#################\n",
    "     #PATHS\n",
    "#################\n",
    "# Define paths used in the project:\n",
    "input_folder = Path('/kaggle/input/')  # Set the path for the input folder where data files are stored.\n",
    "output_folder = Path('/kaggle/working/')  # Set the path for the output folder where results and outputs will be saved.\n",
    "# Define the path to the image classification dataset within the input folder.\n",
    "data_path = input_folder / 'char-class/images-classification'\n",
    "# Load the dataset from the specified directory using a function assumed to handle dataset loading.\n",
    "# The function 'load_dataset' would typically preprocess and ready the dataset for use in training or testing.\n",
    "dataset = load_dataset(data_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8155cb68",
   "metadata": {
    "papermill": {
     "duration": 0.008355,
     "end_time": "2024-06-27T10:38:13.208580",
     "exception": false,
     "start_time": "2024-06-27T10:38:13.200225",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9964e26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T08:10:17.545308Z",
     "iopub.status.busy": "2024-06-27T08:10:17.544577Z",
     "iopub.status.idle": "2024-06-27T08:10:17.552398Z",
     "shell.execute_reply": "2024-06-27T08:10:17.551480Z",
     "shell.execute_reply.started": "2024-06-27T08:10:17.545276Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddbdca5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T08:10:18.967653Z",
     "iopub.status.busy": "2024-06-27T08:10:18.967290Z",
     "iopub.status.idle": "2024-06-27T08:10:18.973502Z",
     "shell.execute_reply": "2024-06-27T08:10:18.972592Z",
     "shell.execute_reply.started": "2024-06-27T08:10:18.967618Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2755fff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_with_label(X, y, index):\n",
    "    # Retrieve the image and label from the dataset using the provided index.\n",
    "    image = X[index]\n",
    "    label = y[index]\n",
    "\n",
    "    # Reverse normalization to display the image correctly if it was normalized between -1 and 1.\n",
    "    image = (image + 1) / 2.0\n",
    "\n",
    "    # Use matplotlib to display the image.\n",
    "    plt.imshow(image.squeeze())  # Squeeze is used to remove single-dimensional entries from the shape of the image.\n",
    "    plt.title(f'Label: {label} | Dimensions: {image.shape}')  # Set the title of the plot to show the label and image dimensions.\n",
    "    plt.axis('off')  # Turn off the axis.\n",
    "    plt.show()  # Display the plot.\n",
    "\n",
    "    # Print additional information about the image.\n",
    "    print(f\"Image array (index {index}):\\n\", image)\n",
    "    print(f\"Label: {label}\")\n",
    "    print(f\"Dimensions: {image.shape}\")\n",
    "\n",
    "# Load the training dataset (assuming 'dataset' is a tuple of (X_train, y_train)).\n",
    "X_train, y_train = dataset\n",
    "\n",
    "# Display the first image and its label using the function.\n",
    "show_image_with_label(X_train, y_train, 3988)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ea9cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T08:10:23.417385Z",
     "iopub.status.busy": "2024-06-27T08:10:23.416896Z",
     "iopub.status.idle": "2024-06-27T08:10:23.424863Z",
     "shell.execute_reply": "2024-06-27T08:10:23.423940Z",
     "shell.execute_reply.started": "2024-06-27T08:10:23.417350Z"
    },
    "executionInfo": {
     "elapsed": 628,
     "status": "error",
     "timestamp": 1718628250325,
     "user": {
      "displayName": "Clémence F",
      "userId": "02328509030226210452"
     },
     "user_tz": -120
    },
    "id": "eitdRqwTMVuq",
    "outputId": "7cb35543-7fb5-46bd-c804-2830daf56b3d",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_results(images, n_cols=None):\n",
    "    \"\"\"\n",
    "    Displays a list of images in a grid format.\n",
    "\n",
    "    Parameters:\n",
    "    - images (list of np.array): A list of images (as numpy arrays) normalized between [-1, 1].\n",
    "    - n_cols (int, optional): The number of columns in the grid display. If not specified, the number\n",
    "      of columns will be equal to the number of images, resulting in a single row.\n",
    "\n",
    "    This function converts images from a [-1, 1] normalization to [0, 1] by adding 1 and dividing by 2,\n",
    "    which is suitable for displaying with imshow that expects values between [0, 1].\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine the number of columns and rows for the display\n",
    "    n_cols = n_cols or len(images)  # If n_cols is not specified, use the total number of images\n",
    "    n_rows = (len(images) - 1) // n_cols + 1  # Calculate the necessary number of rows\n",
    "\n",
    "    # Normalize the images from [-1, 1] to [0, 1]\n",
    "    images = (images + 1.0) / 2.0  # Prepare images for correct display\n",
    "\n",
    "    # Configure the figure size based on the number of columns and rows\n",
    "    plt.figure(figsize=(2 * n_cols, 2 * n_rows))  # Adjust figure size for better visibility\n",
    "\n",
    "    # Display each image from the list\n",
    "    for index, image in enumerate(images):\n",
    "        plt.subplot(n_rows, n_cols, index + 1)  # Create a subplot for each image\n",
    "        plt.imshow(image)  # Display the image\n",
    "        plt.axis(\"off\")  # Hide the axes to focus only on the images\n",
    "\n",
    "    plt.show()  # Show the final result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1cc3f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T08:10:24.945979Z",
     "iopub.status.busy": "2024-06-27T08:10:24.945617Z",
     "iopub.status.idle": "2024-06-27T08:10:24.952961Z",
     "shell.execute_reply": "2024-06-27T08:10:24.951993Z",
     "shell.execute_reply.started": "2024-06-27T08:10:24.945951Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_dataset_samples(dataset, n_samples):\n",
    "    \"\"\"\n",
    "    Randomly selects a subset of samples from a dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset (tuple): A tuple containing two elements: the images and the labels.\n",
    "    - n_samples (int): The number of samples to select.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple ([X, labels], y) where 'X' are the selected images, 'labels' are the corresponding labels,\n",
    "      and 'y' is an array of ones (often used for specific tasks).\n",
    "\n",
    "    The function assumes that 'dataset' is a tuple where the first element is an array of images and the\n",
    "    second element is an array of labels. It returns a specified subset of these images and labels.\n",
    "    \"\"\"\n",
    "\n",
    "    # Decompose the dataset into images and labels\n",
    "    images, labels = dataset\n",
    "\n",
    "    # Generate random indices for the selection of samples\n",
    "    ix = np.random.randint(0, images.shape[0], n_samples)\n",
    "\n",
    "    # Select the images and corresponding labels\n",
    "    X, labels = images[ix], labels[ix]\n",
    "\n",
    "    # Create an array of ones for potential use (depending on the usage context)\n",
    "    y = np.ones((n_samples, 1))\n",
    "\n",
    "    return [X, labels], y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f0c308",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T08:10:26.169204Z",
     "iopub.status.busy": "2024-06-27T08:10:26.168280Z",
     "iopub.status.idle": "2024-06-27T08:10:26.177303Z",
     "shell.execute_reply": "2024-06-27T08:10:26.176446Z",
     "shell.execute_reply.started": "2024-06-27T08:10:26.169169Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_noise(noise_size, n_samples, n_classes=10):\n",
    "    \"\"\"\n",
    "    Generates a noise dataset with corresponding random class labels.\n",
    "\n",
    "    Parameters:\n",
    "    - noise_size (int): The size of the noise vector for each sample.\n",
    "    - n_samples (int): The number of samples to generate.\n",
    "    - n_classes (int, optional): The number of classes to generate labels for, defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple ([z_input, labels]) where 'z_input' is a matrix of noise vectors and 'labels' is an array of random class labels.\n",
    "\n",
    "    Cette fonction génère un ensemble de données de bruit avec des étiquettes de classe aléatoires correspondantes.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate random Gaussian noise\n",
    "    x_input = np.random.randn(noise_size * n_samples)  # Generate Gaussian noise\n",
    "    z_input = x_input.reshape(n_samples, noise_size)  # Reshape to form a matrix\n",
    "\n",
    "    # Generate random labels for each sample\n",
    "    labels = np.random.randint(0, n_classes, n_samples)  # Random integer labels from 0 to n_classes-1\n",
    "\n",
    "    return [z_input, labels]\n",
    "\n",
    "# Example of using the function:\n",
    "noise_size = 100  # Size of the noise vector\n",
    "n_samples = 64   # Number of samples to generate\n",
    "n_classes = 10   # Number of classes\n",
    "\n",
    "noise_data = generate_noise(noise_size, n_samples, n_classes)\n",
    "print(noise_data[0].shape)  # Prints the shape of the noise matrix\n",
    "print(noise_data[1].shape)  # Prints the shape of the labels array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f15f1f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T08:10:29.295357Z",
     "iopub.status.busy": "2024-06-27T08:10:29.295016Z",
     "iopub.status.idle": "2024-06-27T08:10:29.301987Z",
     "shell.execute_reply": "2024-06-27T08:10:29.301120Z",
     "shell.execute_reply.started": "2024-06-27T08:10:29.295332Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    \"\"\"\n",
    "    Generates fake samples using a generator model from a GAN.\n",
    "\n",
    "    Parameters:\n",
    "    - generator (Model): The generator model from a GAN setup that takes noise and labels as input.\n",
    "    - latent_dim (int): The size of the latent space (dimensionality of the noise vector).\n",
    "    - n_samples (int): The number of fake samples to generate.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing the generated fake samples and their corresponding labels:\n",
    "      ([images, labels_input], y) where 'images' are the generated images, 'labels_input' are the random class labels,\n",
    "      and 'y' is an array of zeros indicating the samples are fake.\n",
    "    \n",
    "    Utilise un modèle générateur pour transformer des entrées de bruit en données synthétiques (images),\n",
    "    et génère également des étiquettes indiquant que ces échantillons sont 'faux'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate noise and labels\n",
    "    z_input, labels_input = generate_noise(latent_dim, n_samples)  # Use the helper function to generate inputs\n",
    "\n",
    "    # Generate fake images using the generator model\n",
    "    images = generator.predict([z_input, labels_input])  # Predict (generate) images using the generator\n",
    "\n",
    "    # Create an array of zeros to label the generated images as fake\n",
    "    y = np.zeros((n_samples, 1))  # Labels for the GAN discriminator (0 = fake)\n",
    "\n",
    "    return [images, labels_input], y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97930427",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T08:10:31.539044Z",
     "iopub.status.busy": "2024-06-27T08:10:31.538448Z",
     "iopub.status.idle": "2024-06-27T08:10:31.549060Z",
     "shell.execute_reply": "2024-06-27T08:10:31.548206Z",
     "shell.execute_reply.started": "2024-06-27T08:10:31.539010Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_generator(latent_dim, n_classes=24):\n",
    "    # Input layer for the label, one-hot encoded.\n",
    "    in_label = keras.layers.Input(shape=(1,))\n",
    "    # Embedding layer to transform the label into a dense representation.\n",
    "    li = keras.layers.Embedding(n_classes, 50)(in_label)\n",
    "    # Define the number of nodes to match the image structure expected later.\n",
    "    n_nodes = 7 * 7\n",
    "    # Dense layer to expand the label embedding.\n",
    "    li = keras.layers.Dense(n_nodes)(li)\n",
    "    # Reshape the output to be compatible with the image structure.\n",
    "    li = keras.layers.Reshape((7, 7, 1))(li)\n",
    "    \n",
    "    # Input layer for generating images from the latent space.\n",
    "    in_lat = keras.layers.Input(shape=(latent_dim,))\n",
    "    # Define the number of nodes for the generator's first layer.\n",
    "    n_nodes = 128 * 7 * 7\n",
    "    # Dense layer to process the input latent vector.\n",
    "    gen = keras.layers.Dense(n_nodes)(in_lat)\n",
    "    # LeakyReLU for non-linearity while allowing small gradients when the unit is not active.\n",
    "    gen = keras.layers.LeakyReLU(alpha=0.2)(gen)\n",
    "    # Reshape to start forming the image.\n",
    "    gen = keras.layers.Reshape((7, 7, 128))(gen)\n",
    "\n",
    "    # Concatenate the label conditioning and the latent input into a single tensor.\n",
    "    merge = keras.layers.Concatenate()([gen, li])\n",
    "    # First transposed convolution layer to upscale the image.\n",
    "    gen = keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same',\n",
    "                                       activation=keras.layers.LeakyReLU(alpha=0.2))(merge)\n",
    "    # Batch normalization to stabilize learning.\n",
    "    gen = keras.layers.BatchNormalization()(gen)\n",
    "    # Second transposed convolution layer to continue upscaling.\n",
    "    gen = keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same',\n",
    "                                       activation=keras.layers.LeakyReLU(alpha=0.2))(gen)\n",
    "    # Batch normalization layer.\n",
    "    gen = keras.layers.BatchNormalization()(gen)\n",
    "    # Output convolution layer that converts the image tensor to the final image shape with 3 channels.\n",
    "    out_layer = keras.layers.Conv2D(3, (3,3), activation='tanh', padding='same')(gen)\n",
    "\n",
    "    # Create the model object that takes two inputs and outputs the generated image.\n",
    "    model = keras.Model([in_lat, in_label], out_layer)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafae135",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T08:10:32.479805Z",
     "iopub.status.busy": "2024-06-27T08:10:32.479008Z",
     "iopub.status.idle": "2024-06-27T08:10:32.489969Z",
     "shell.execute_reply": "2024-06-27T08:10:32.488962Z",
     "shell.execute_reply.started": "2024-06-27T08:10:32.479772Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_generator(noise_dim=100, n_classes=10):\n",
    "    # Inputs: a label and a noise vector. The label is embedded and reshaped to match the dimensionality of the transformation process.\n",
    "    label_input = keras.layers.Input(shape=(1,), dtype='int32')\n",
    "    label_embedding = keras.layers.Embedding(n_classes, noise_dim)(label_input)\n",
    "    label_reshape = keras.layers.Reshape((8, 8, 1))(keras.layers.Dense(8 * 8)(label_embedding))\n",
    "\n",
    "    # Process the noise vector to generate features for the generator.\n",
    "    noise_input = keras.layers.Input(shape=(noise_dim,))\n",
    "    noise_reshape = keras.layers.Reshape((8, 8, 128))(keras.layers.Dense(8 * 8 * 128)(noise_input))\n",
    "\n",
    "    # Merge the noise-derived features and label-derived features.\n",
    "    merged = keras.layers.Concatenate()([noise_reshape, label_reshape])\n",
    "\n",
    "    # Convolutional layers to upsample the combined feature map to the target image size.\n",
    "    gen = keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(merged)\n",
    "    gen = keras.layers.LeakyReLU(alpha=0.2)(gen)  # Repeatedly upsample and apply LeakyReLU.\n",
    "\n",
    "    # Final convolutional layer to produce the output image with 3 color channels (RGB), using the 'tanh' activation to scale the pixel values between -1 and 1.\n",
    "    out_layer = keras.layers.Conv2D(3, (3,3), activation='tanh', padding='same')(gen)\n",
    "\n",
    "    # Assemble the model with noise and label inputs.\n",
    "    model = keras.Model([noise_input, label_input], out_layer)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe85ca0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T08:10:37.242123Z",
     "iopub.status.busy": "2024-06-27T08:10:37.241348Z",
     "iopub.status.idle": "2024-06-27T08:10:37.371166Z",
     "shell.execute_reply": "2024-06-27T08:10:37.370320Z",
     "shell.execute_reply.started": "2024-06-27T08:10:37.242078Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "noise_size = 100\n",
    "\n",
    "generator = define_generator(noise_size)\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ee74d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T08:10:38.574971Z",
     "iopub.status.busy": "2024-06-27T08:10:38.574632Z",
     "iopub.status.idle": "2024-06-27T08:10:38.585109Z",
     "shell.execute_reply": "2024-06-27T08:10:38.584183Z",
     "shell.execute_reply.started": "2024-06-27T08:10:38.574944Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_discriminator(in_shape=(64, 64, 3), n_classes=24):\n",
    "    # Input for the label, embedded to a dense representation suitable for merging with image data.\n",
    "    in_label = keras.layers.Input(shape=(1,))\n",
    "    li = keras.layers.Embedding(n_classes, 50)(in_label)\n",
    "    n_nodes = in_shape[0] * in_shape[1]\n",
    "    li = keras.layers.Dense(n_nodes)(li)\n",
    "    li = keras.layers.Reshape((in_shape[0], in_shape[1], 1))(li)\n",
    "\n",
    "    # Input for the image.\n",
    "    in_image = keras.layers.Input(shape=in_shape)\n",
    "\n",
    "    # Merge the image and label inputs to form the combined feature map.\n",
    "    merge = keras.layers.Concatenate()([in_image, li])\n",
    "\n",
    "    # Convolutional layers to downsample the input and extract features, with dropout for regularization.\n",
    "    fe = keras.layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', activation=keras.layers.LeakyReLU(alpha=0.2))(merge)\n",
    "    fe = keras.layers.Dropout(0.4)(fe)\n",
    "    fe = keras.layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', activation=keras.layers.LeakyReLU(alpha=0.2))(fe)\n",
    "    fe = keras.layers.Dropout(0.4)(fe)\n",
    "\n",
    "    # Flatten the feature map and use a dense layer to output a single value indicating real or fake.\n",
    "    fe = keras.layers.Flatten()(fe)\n",
    "    out_layer = keras.layers.Dense(1, activation='sigmoid')(fe)\n",
    "\n",
    "    # Create the model with image and label as inputs.\n",
    "    model = keras.Model([in_image, in_label], out_layer)\n",
    "\n",
    "    # Compile the model with the Adam optimizer and binary crossentropy loss, also tracking accuracy.\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265258f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T08:10:39.560702Z",
     "iopub.status.busy": "2024-06-27T08:10:39.560342Z",
     "iopub.status.idle": "2024-06-27T08:10:39.652302Z",
     "shell.execute_reply": "2024-06-27T08:10:39.651431Z",
     "shell.execute_reply.started": "2024-06-27T08:10:39.560672Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "discriminator = define_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad283bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T08:10:40.668971Z",
     "iopub.status.busy": "2024-06-27T08:10:40.668624Z",
     "iopub.status.idle": "2024-06-27T08:10:40.674993Z",
     "shell.execute_reply": "2024-06-27T08:10:40.673968Z",
     "shell.execute_reply.started": "2024-06-27T08:10:40.668943Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_gan(generator, discriminator):\n",
    "    # Ensure the discriminator's weights are not updated during the combined model's training.\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    # Retrieve the input layers from the generator model.\n",
    "    gen_noise, gen_label = generator.input\n",
    "\n",
    "    # Get the output from the generator model.\n",
    "    gen_output = generator.output\n",
    "\n",
    "    # Feed the generator's output along with the label input into the discriminator.\n",
    "    gan_output = discriminator([gen_output, gen_label])\n",
    "\n",
    "    # Define the GAN model with noise and label inputs leading to the discriminator's output.\n",
    "    model = keras.Model([gen_noise, gen_label], gan_output)\n",
    "\n",
    "    # Configure the model using the Adam optimizer and compile it with binary cross-entropy loss.\n",
    "    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ba747a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T08:10:43.073564Z",
     "iopub.status.busy": "2024-06-27T08:10:43.072953Z",
     "iopub.status.idle": "2024-06-27T08:10:43.116986Z",
     "shell.execute_reply": "2024-06-27T08:10:43.116183Z",
     "shell.execute_reply.started": "2024-06-27T08:10:43.073531Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GAN = define_gan(generator, discriminator)\n",
    "GAN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a6ccac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T08:10:44.834069Z",
     "iopub.status.busy": "2024-06-27T08:10:44.833711Z",
     "iopub.status.idle": "2024-06-27T08:10:45.053844Z",
     "shell.execute_reply": "2024-06-27T08:10:45.052958Z",
     "shell.execute_reply.started": "2024-06-27T08:10:44.834039Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4205f22a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T08:10:47.185399Z",
     "iopub.status.busy": "2024-06-27T08:10:47.184789Z",
     "iopub.status.idle": "2024-06-27T08:10:47.193374Z",
     "shell.execute_reply": "2024-06-27T08:10:47.192496Z",
     "shell.execute_reply.started": "2024-06-27T08:10:47.185357Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, GAN, dataset, noise_size=100, n_epochs=30, n_batch=16):\n",
    "    # Calculate the number of steps per epoch based on batch size and dataset size.\n",
    "    steps = int(dataset[0].shape[0] / n_batch)\n",
    "    # Define half batch size for training the discriminator on real and fake data separately.\n",
    "    half_batch = int(n_batch / 2)\n",
    "\n",
    "    # Loop through each epoch.\n",
    "    for e in range(n_epochs):\n",
    "        print(\"EPOCH\", e)\n",
    "        # Loop through each step within the epoch.\n",
    "        for s in range(steps):\n",
    "            # Get a subset of real samples from the dataset.\n",
    "            [X_real, labels_real], y_real = get_dataset_samples(dataset, half_batch)\n",
    "            # Train the discriminator on real data.\n",
    "            d_loss1, _ = discriminator.train_on_batch([X_real, labels_real], y_real)\n",
    "\n",
    "            # Generate a set of fake samples.\n",
    "            [X_fake, labels], y_fake = generate_fake_samples(generator, noise_size, half_batch)\n",
    "            # Train the discriminator on fake data.\n",
    "            d_loss2, _ = discriminator.train_on_batch([X_fake, labels], y_fake)\n",
    "\n",
    "            # Generate noise and corresponding labels for the generator input.\n",
    "            [z_input, labels_input] = generate_noise(noise_size, n_batch)\n",
    "            # All labels for GAN training are set to one (as GAN's output should be seen as 'real').\n",
    "            y_gan = np.ones((n_batch, 1))\n",
    "            # Train the GAN by updating the generator via the discriminator’s error.\n",
    "            g_loss = GAN.train_on_batch([z_input, labels_input], y_gan)\n",
    "            # Optional: Uncomment to print losses for each step.\n",
    "            # print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' % (e+1, s+1, steps, d_loss1, d_loss2, g_loss))\n",
    "        \n",
    "        # Display generated images from the last batch of the epoch.\n",
    "        plot_results(X_fake, 8)  \n",
    "    \n",
    "    # Save the generator model at the end of training.\n",
    "    generator.save('cgan_generator.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214c8b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd28f44",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the GAN model with the following parameters:\n",
    "# - generator: the generator model to produce fake samples.\n",
    "# - discriminator: the discriminator model to evaluate real and fake samples.\n",
    "# - GAN: the combined model that connects the generator and discriminator.\n",
    "# - dataset: the dataset used for training, containing real samples and their labels.\n",
    "# - noise_size: the size of the noise vector used by the generator to create samples.\n",
    "# - n_epochs: the number of epochs for training, set to 1 in this call.\n",
    "# - n_batch: the batch size for training, set to 16.\n",
    "\n",
    "train_gan(generator, discriminator, GAN, dataset, noise_size, n_epochs=1, n_batch=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62666e2",
   "metadata": {
    "executionInfo": {
     "elapsed": 1161,
     "status": "error",
     "timestamp": 1718630740244,
     "user": {
      "displayName": "Clémence F",
      "userId": "02328509030226210452"
     },
     "user_tz": -120
    },
    "id": "omfGxznMMVzy",
    "outputId": "956d3fa2-d47e-4659-afad-02f13f5be9ba",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained GAN generator model from the specified file.\n",
    "model = keras.models.load_model('cgan_generator.h5')\n",
    "\n",
    "# Generate noise and labels for creating new samples.\n",
    "# 'noise_size' specifies the dimensionality of the noise vector.\n",
    "# 'generate_noise' creates 20 noise vectors and corresponding labels.\n",
    "latent_points, labels = generate_noise(noise_size, 20)\n",
    "\n",
    "# Set all labels to 0 for the generated samples.\n",
    "labels = np.ones(20) * 0\n",
    "\n",
    "# Use the generator model to predict (generate) new images based on the noise and labels.\n",
    "X = model.predict([latent_points, labels])\n",
    "\n",
    "# Plot and display the generated images in a grid format.\n",
    "plot_results(X, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c86273",
   "metadata": {
    "executionInfo": {
     "elapsed": 2252,
     "status": "ok",
     "timestamp": 1718630936172,
     "user": {
      "displayName": "Clémence F",
      "userId": "02328509030226210452"
     },
     "user_tz": -120
    },
    "id": "L3ClqgqAYCsn",
    "outputId": "1d2f0366-e2cb-4f04-a344-6b4dd06bbaa2",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate noise and labels for prediction\n",
    "latent_points, labels = generate_noise(100, 20)  # Use noise dimension 100\n",
    "\n",
    "# Assuming you want to generate images with label 0\n",
    "labels = np.ones(latent_points.shape[0]) * 1  # Set labels for all generated noise points to 0\n",
    "\n",
    "# Generate images\n",
    "X = model.predict([latent_points, labels])\n",
    "\n",
    "# Plot the generated images\n",
    "plot_results(X, int(np.sqrt(X.shape[0])))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNLsFrD2txhejIW6ZVikqBy",
   "provenance": [
    {
     "file_id": "1WEX6pIw94l_pDzbt4lXaAqf9ibmMAf-1",
     "timestamp": 1718624965931
    }
   ]
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 185439535,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19.161031,
   "end_time": "2024-06-27T10:38:16.478553",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-27T10:37:57.317522",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
